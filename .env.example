# Example environment variables for local testing
# Copy this file to .env and fill in your actual values

# Required: Your LLM API key
# For OpenAI: https://platform.openai.com/api-keys
# For Anthropic: https://console.anthropic.com/settings/keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# Optional: Alternative API key name
# LLM_API_KEY=your-api-key-here

# Optional: Custom LLM endpoint (defaults to OpenAI)
# For OpenAI: https://api.openai.com/v1
# For Anthropic: https://api.anthropic.com/v1
# For Ollama: http://localhost:11434/v1
# For Azure: https://your-resource.openai.azure.com/openai/deployments/your-deployment
LLM_BASE_URL=https://api.openai.com/v1

# Optional: Model to use (defaults to gpt-4o-mini for testing)
# OpenAI models: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo
# Anthropic models: claude-3-5-sonnet-20241022, claude-3-opus-20240229
# Ollama models: codellama, llama2, mistral
LLM_MODEL=gpt-4o-mini

# Optional: Review mode
# Options: summary, detailed, security, performance
REVIEW_MODE=detailed

# Optional: Maximum files to review (0 for unlimited)
MAX_FILES=10

# Optional: Custom prompt (leave empty to use default)
# PROMPT=Your custom review prompt here

# Optional: GitHub token (not needed for local testing with mock client)
# GITHUB_TOKEN=ghp_your-token-here
